# Continuous Integration Workflow for photon-mlir-bridge
# This file should be placed at: .github/workflows/ci.yml

name: CI

on:
  push:
    branches: [ main, develop ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - '.gitignore'
  pull_request:
    branches: [ main, develop ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - '.gitignore'
  workflow_dispatch:
    inputs:
      debug_enabled:
        description: 'Enable debugging'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  CMAKE_BUILD_TYPE: Release
  CACHE_VERSION: v1

permissions:
  contents: read
  issues: read
  checks: write
  pull-requests: write

jobs:
  # Pre-flight checks - fast feedback
  pre-flight:
    name: Pre-flight Checks
    runs-on: ubuntu-22.04
    timeout-minutes: 10
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install pre-commit
        run: |
          python -m pip install --upgrade pip
          pip install pre-commit

      - name: Run pre-commit
        run: pre-commit run --all-files --show-diff-on-failure

      - name: Check commit messages
        run: |
          # Check conventional commit format
          git log --oneline -10 --pretty=format:"%s" | \
            grep -E "^(feat|fix|docs|style|refactor|test|build|ci|perf|chore)(\(.+\))?: .{1,50}$" || \
            echo "Warning: Some commits don't follow conventional format"

  # Matrix testing across environments
  test-matrix:
    name: Test (${{ matrix.os }}, Python ${{ matrix.python-version }})
    runs-on: ${{ matrix.os }}
    needs: pre-flight
    timeout-minutes: 45
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-22.04, macos-13, windows-2022]
        python-version: ['3.9', '3.10', '3.11', '3.12']
        exclude:
          # Reduce matrix size - test Python 3.9 only on Ubuntu
          - os: macos-13
            python-version: '3.9'
          - os: windows-2022
            python-version: '3.9'
          # Skip Python 3.12 on macOS until MLIR support is stable
          - os: macos-13
            python-version: '3.12'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      # Platform-specific MLIR/LLVM installation
      - name: Install MLIR/LLVM (Ubuntu)
        if: matrix.os == 'ubuntu-22.04'
        run: |
          wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -
          echo "deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-17 main" | sudo tee /etc/apt/sources.list.d/llvm.list
          sudo apt-get update
          sudo apt-get install -y \
            llvm-17-dev \
            mlir-17-tools \
            libmlir-17-dev \
            clang-17 \
            libedit-dev

      - name: Install MLIR/LLVM (macOS)
        if: matrix.os == 'macos-13'
        run: |
          brew install llvm@17
          echo "/opt/homebrew/opt/llvm@17/bin" >> $GITHUB_PATH
          echo "LLVM_DIR=/opt/homebrew/opt/llvm@17/lib/cmake/llvm" >> $GITHUB_ENV
          echo "MLIR_DIR=/opt/homebrew/opt/llvm@17/lib/cmake/mlir" >> $GITHUB_ENV

      - name: Install MLIR/LLVM (Windows)
        if: matrix.os == 'windows-2022'
        run: |
          # Download and install LLVM pre-built binaries
          Invoke-WebRequest -Uri "https://github.com/llvm/llvm-project/releases/download/llvmorg-17.0.6/LLVM-17.0.6-win64.exe" -OutFile "llvm-installer.exe"
          Start-Process -FilePath "llvm-installer.exe" -ArgumentList "/S" -Wait
          echo "C:\Program Files\LLVM\bin" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append

      - name: Cache CMake build
        uses: actions/cache@v3
        with:
          path: |
            build
            ~/.cache/cmake
          key: cmake-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('CMakeLists.txt', 'cmake/**') }}-${{ env.CACHE_VERSION }}
          restore-keys: |
            cmake-${{ runner.os }}-${{ matrix.python-version }}-
            cmake-${{ runner.os }}-

      # Install Python dependencies
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -e ".[dev,test,docs]"

      # Build C++ components
      - name: Configure CMake
        run: |
          mkdir -p build
          cd build
          cmake .. \
            -DCMAKE_BUILD_TYPE=${{ env.CMAKE_BUILD_TYPE }} \
            -DPHOTON_ENABLE_TESTS=ON \
            -DPHOTON_ENABLE_PYTHON=ON \
            -DPHOTON_ENABLE_BENCHMARKS=ON

      - name: Build C++ components
        run: |
          cd build
          cmake --build . --parallel $(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo 2)

      # Run tests
      - name: Run C++ tests
        run: |
          cd build
          ctest --output-on-failure --parallel $(nproc 2>/dev/null || sysctl -n hw.ncpu 2>/dev/null || echo 2)

      - name: Run Python tests
        run: |
          pytest tests/ \
            --verbose \
            --cov=photon_mlir \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=pytest-results.xml

      # Upload test results
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ matrix.os }}-py${{ matrix.python-version }}
          path: |
            pytest-results.xml
            coverage.xml
            build/Testing/

      - name: Upload coverage to Codecov
        if: matrix.os == 'ubuntu-22.04' && matrix.python-version == '3.11'
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  # Security and quality checks
  security-quality:
    name: Security & Quality
    runs-on: ubuntu-22.04
    needs: pre-flight
    timeout-minutes: 30
    
    permissions:
      security-events: write
      actions: read
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install security tools
        run: |
          python -m pip install --upgrade pip
          pip install bandit[toml] safety semgrep

      # Python security scanning
      - name: Run Bandit security scan
        run: |
          bandit -r python/ -f json -o bandit-results.json || true
          bandit -r python/ -f txt

      - name: Run Safety check
        run: |
          safety check --json --output safety-results.json || true
          safety check

      - name: Run Semgrep
        run: |
          semgrep --config=auto python/ --json --output=semgrep-results.json || true

      # CodeQL Analysis
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v2
        with:
          languages: python, cpp
          queries: security-and-quality

      - name: Autobuild
        uses: github/codeql-action/autobuild@v2

      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v2
        with:
          category: "/language:python"

      # Upload security results
      - name: Upload security results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: security-results
          path: |
            bandit-results.json
            safety-results.json
            semgrep-results.json

  # Build documentation
  documentation:
    name: Build Documentation
    runs-on: ubuntu-22.04
    needs: pre-flight
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install documentation dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[docs]"

      - name: Build documentation
        run: |
          cd docs
          make html SPHINXOPTS="-W --keep-going"

      - name: Upload documentation
        uses: actions/upload-artifact@v3
        with:
          name: documentation
          path: docs/_build/html/

  # Performance benchmarking (only on main branch)
  performance:
    name: Performance Benchmarks
    runs-on: ubuntu-22.04
    needs: [test-matrix, security-quality]
    if: github.ref == 'refs/heads/main'
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install MLIR/LLVM
        run: |
          wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -
          echo "deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-17 main" | sudo tee /etc/apt/sources.list.d/llvm.list
          sudo apt-get update
          sudo apt-get install -y llvm-17-dev mlir-17-tools libmlir-17-dev clang-17

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[test,benchmark]"

      - name: Build optimized version
        run: |
          mkdir -p build
          cd build
          cmake .. \
            -DCMAKE_BUILD_TYPE=Release \
            -DPHOTON_ENABLE_BENCHMARKS=ON \
            -DPHOTON_ENABLE_TESTS=ON
          cmake --build . --parallel $(nproc)

      - name: Run benchmarks
        run: |
          cd build
          ./tests/benchmarks/photon_benchmarks \
            --benchmark_format=json \
            --benchmark_out=benchmark_results.json

      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-results
          path: build/benchmark_results.json

      # Compare with baseline (if available)
      - name: Download baseline benchmarks
        continue-on-error: true
        uses: dawidd6/action-download-artifact@v2
        with:
          workflow: ci.yml
          branch: main
          name: benchmark-results
          path: baseline/
          if_no_artifact_found: warn

      - name: Compare benchmarks
        if: hashFiles('baseline/benchmark_results.json') != ''
        run: |
          python scripts/compare_benchmarks.py \
            baseline/benchmark_results.json \
            build/benchmark_results.json \
            --output benchmark_comparison.md

      - name: Comment benchmark results
        if: github.event_name == 'pull_request' && hashFiles('benchmark_comparison.md') != ''
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const comparison = fs.readFileSync('benchmark_comparison.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## 🏃‍♂️ Performance Benchmark Results\n\n${comparison}`
            });

  # Final status check
  ci-success:
    name: CI Success
    runs-on: ubuntu-22.04
    needs: [test-matrix, security-quality, documentation]
    if: always()
    
    steps:
      - name: Check all jobs success
        if: contains(needs.*.result, 'failure') || contains(needs.*.result, 'cancelled')
        run: |
          echo "One or more jobs failed or were cancelled"
          exit 1
      
      - name: CI completed successfully
        run: |
          echo "All CI jobs completed successfully! 🎉"